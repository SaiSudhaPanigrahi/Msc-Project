{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Fashion MNIST by moti",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/motkeg/Msc-Project/blob/fashion_mnist/Keras_fashion_mnist_cnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ot79jiI7GiHR"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST with Keras and TPUs\n",
        "\n",
        "Let's try out using `tf.keras` and Cloud TPUs to train a model on the fashion MNIST dataset.\n",
        "\n",
        "First, let's grab our dataset using `tf.keras.datasets`."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Zo-Yk6LFGfSf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard , ModelCheckpoint\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Hgc2FZKVMx15"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining our model\n",
        "\n",
        "We will use a standard conv-net for this example.  We have 3 layers with drop-out and batch normalization between each layer."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W7gMbs70GxA7",
        "outputId": "9c638242-17dc-4ed0-b212-7515b8e37aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 256)         819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xLeZATVaNAnE"
      },
      "cell_type": "markdown",
      "source": [
        "# Training on the TPU\n",
        "\n",
        "We're ready to train!   We first construct our model on the TPU, and compile it.\n",
        "\n",
        "Here we demonstrate that we can use a generator function and `fit_generator` to train the model.  You can also pass in `x_train` and `y_train` to `tpu_model.fit()` instead."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pWEYmd_hIWg8",
        "outputId": "f47b10b1-a7ad-4cbb-9354-215925023f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5851
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "print('ADDR: grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tpu_model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "def train_gen(batch_size):\n",
        "  while True:\n",
        "    offset = np.random.randint(0, x_train.shape[0] - batch_size)\n",
        "    yield x_train[offset:offset+batch_size], y_train[offset:offset + batch_size]\n",
        "    \n",
        "\n",
        "# define tensorboard and checkpointer\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"./logs/\",\n",
        "                          batch_size=128,\n",
        "                            write_graph=True,\n",
        "                            histogram_freq=3,\n",
        "                            write_images=True,\n",
        "                            write_grads=True)  \n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"./output/weights.best.hdf5\", \n",
        "                               verbose = 1) \n",
        "\n",
        "tpu_model.fit(x_train , y_train,\n",
        "              batch_size=128,           \n",
        "              epochs=50,\n",
        "              shuffle=True,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[checkpointer])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.0.254.58:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 14964223317027243506)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9700572122796800097)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 7314772714797842084)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2898408116508465878)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5922345768123879840)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6398495586556769839)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1228780395877564944)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7974867972103694562)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 14354669032654471378)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3938323741246042066)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16413504384983916298)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9352862986552536845)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "ADDR: grpc://10.0.254.58:8470\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(16, 28, 28, 1), dtype=tf.float32, name='batch_normalization_input_10'), TensorSpec(shape=(16, 1), dtype=tf.float32, name='activation_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 3.2696006298065186 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.6198 - sparse_categorical_accuracy: 0.7778INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(12,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(12, 28, 28, 1), dtype=tf.float32, name='batch_normalization_input_10'), TensorSpec(shape=(12, 1), dtype=tf.float32, name='activation_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.781888008117676 secs\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.6198 - sparse_categorical_accuracy: 0.7779INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(16, 28, 28, 1), dtype=tf.float32, name='batch_normalization_input_10'), TensorSpec(shape=(16, 1), dtype=tf.float32, name='activation_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.8084824085235596 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(2,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(2, 28, 28, 1), dtype=tf.float32, name='batch_normalization_input_10'), TensorSpec(shape=(2, 1), dtype=tf.float32, name='activation_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 3.5420475006103516 secs\n",
            "\n",
            "Epoch 00001: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 47s 787us/step - loss: 0.6196 - sparse_categorical_accuracy: 0.7781 - val_loss: 0.4142 - val_sparse_categorical_accuracy: 0.8428\n",
            "Epoch 2/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.3958 - sparse_categorical_accuracy: 0.8574\n",
            "Epoch 00002: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.3957 - sparse_categorical_accuracy: 0.8574 - val_loss: 0.3079 - val_sparse_categorical_accuracy: 0.8906\n",
            "Epoch 3/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.3296 - sparse_categorical_accuracy: 0.8812\n",
            "Epoch 00003: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 447us/step - loss: 0.3295 - sparse_categorical_accuracy: 0.8813 - val_loss: 0.3055 - val_sparse_categorical_accuracy: 0.8896\n",
            "Epoch 4/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2966 - sparse_categorical_accuracy: 0.8924\n",
            "Epoch 00004: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 444us/step - loss: 0.2967 - sparse_categorical_accuracy: 0.8923 - val_loss: 0.2772 - val_sparse_categorical_accuracy: 0.8958\n",
            "Epoch 5/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2752 - sparse_categorical_accuracy: 0.9015\n",
            "Epoch 00005: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 444us/step - loss: 0.2753 - sparse_categorical_accuracy: 0.9015 - val_loss: 0.2614 - val_sparse_categorical_accuracy: 0.9062\n",
            "Epoch 6/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2611 - sparse_categorical_accuracy: 0.9051\n",
            "Epoch 00006: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 447us/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9051 - val_loss: 0.2506 - val_sparse_categorical_accuracy: 0.9098\n",
            "Epoch 7/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2449 - sparse_categorical_accuracy: 0.9110\n",
            "Epoch 00007: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.2449 - sparse_categorical_accuracy: 0.9110 - val_loss: 0.2514 - val_sparse_categorical_accuracy: 0.9075\n",
            "Epoch 8/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2316 - sparse_categorical_accuracy: 0.9163\n",
            "Epoch 00008: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 447us/step - loss: 0.2315 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.2489 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 9/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2257 - sparse_categorical_accuracy: 0.9186\n",
            "Epoch 00009: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 457us/step - loss: 0.2256 - sparse_categorical_accuracy: 0.9186 - val_loss: 0.2450 - val_sparse_categorical_accuracy: 0.9099\n",
            "Epoch 10/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2122 - sparse_categorical_accuracy: 0.9222\n",
            "Epoch 00010: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.2123 - sparse_categorical_accuracy: 0.9221 - val_loss: 0.2839 - val_sparse_categorical_accuracy: 0.9017\n",
            "Epoch 11/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2097 - sparse_categorical_accuracy: 0.9238\n",
            "Epoch 00011: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 453us/step - loss: 0.2097 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.2361 - val_sparse_categorical_accuracy: 0.9160\n",
            "Epoch 12/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1978 - sparse_categorical_accuracy: 0.9282\n",
            "Epoch 00012: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 457us/step - loss: 0.1979 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.2373 - val_sparse_categorical_accuracy: 0.9191\n",
            "Epoch 13/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1903 - sparse_categorical_accuracy: 0.9296\n",
            "Epoch 00013: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 455us/step - loss: 0.1905 - sparse_categorical_accuracy: 0.9296 - val_loss: 0.2336 - val_sparse_categorical_accuracy: 0.9193\n",
            "Epoch 14/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1861 - sparse_categorical_accuracy: 0.9313\n",
            "Epoch 00014: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 456us/step - loss: 0.1861 - sparse_categorical_accuracy: 0.9314 - val_loss: 0.2387 - val_sparse_categorical_accuracy: 0.9189\n",
            "Epoch 15/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1770 - sparse_categorical_accuracy: 0.9354\n",
            "Epoch 00015: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 460us/step - loss: 0.1770 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.2332 - val_sparse_categorical_accuracy: 0.9222\n",
            "Epoch 16/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1712 - sparse_categorical_accuracy: 0.9368\n",
            "Epoch 00016: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.1711 - sparse_categorical_accuracy: 0.9368 - val_loss: 0.2289 - val_sparse_categorical_accuracy: 0.9238\n",
            "Epoch 17/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1646 - sparse_categorical_accuracy: 0.9397\n",
            "Epoch 00017: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.1647 - sparse_categorical_accuracy: 0.9397 - val_loss: 0.2334 - val_sparse_categorical_accuracy: 0.9187\n",
            "Epoch 18/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1615 - sparse_categorical_accuracy: 0.9397\n",
            "Epoch 00018: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 455us/step - loss: 0.1615 - sparse_categorical_accuracy: 0.9396 - val_loss: 0.2423 - val_sparse_categorical_accuracy: 0.9211\n",
            "Epoch 19/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1583 - sparse_categorical_accuracy: 0.9411\n",
            "Epoch 00019: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 458us/step - loss: 0.1583 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.2509 - val_sparse_categorical_accuracy: 0.9175\n",
            "Epoch 20/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1566 - sparse_categorical_accuracy: 0.9416\n",
            "Epoch 00020: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.2446 - val_sparse_categorical_accuracy: 0.9235\n",
            "Epoch 21/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1487 - sparse_categorical_accuracy: 0.9433\n",
            "Epoch 00021: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 469us/step - loss: 0.1487 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.2624 - val_sparse_categorical_accuracy: 0.9220\n",
            "Epoch 22/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1466 - sparse_categorical_accuracy: 0.9468\n",
            "Epoch 00022: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 460us/step - loss: 0.1466 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.2454 - val_sparse_categorical_accuracy: 0.9240\n",
            "Epoch 23/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1454 - sparse_categorical_accuracy: 0.9461\n",
            "Epoch 00023: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 459us/step - loss: 0.1453 - sparse_categorical_accuracy: 0.9461 - val_loss: 0.2335 - val_sparse_categorical_accuracy: 0.9252\n",
            "Epoch 24/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1394 - sparse_categorical_accuracy: 0.9473\n",
            "Epoch 00024: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 468us/step - loss: 0.1394 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.2433 - val_sparse_categorical_accuracy: 0.9273\n",
            "Epoch 25/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1367 - sparse_categorical_accuracy: 0.9497\n",
            "Epoch 00025: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.1370 - sparse_categorical_accuracy: 0.9496 - val_loss: 0.2434 - val_sparse_categorical_accuracy: 0.9271\n",
            "Epoch 26/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1323 - sparse_categorical_accuracy: 0.9505\n",
            "Epoch 00026: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 461us/step - loss: 0.1323 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.2388 - val_sparse_categorical_accuracy: 0.9240\n",
            "Epoch 27/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1306 - sparse_categorical_accuracy: 0.9522\n",
            "Epoch 00027: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.2713 - val_sparse_categorical_accuracy: 0.9202\n",
            "Epoch 28/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1254 - sparse_categorical_accuracy: 0.9538\n",
            "Epoch 00028: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 459us/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2535 - val_sparse_categorical_accuracy: 0.9266\n",
            "Epoch 29/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1272 - sparse_categorical_accuracy: 0.9527\n",
            "Epoch 00029: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.1272 - sparse_categorical_accuracy: 0.9527 - val_loss: 0.2442 - val_sparse_categorical_accuracy: 0.9221\n",
            "Epoch 30/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1204 - sparse_categorical_accuracy: 0.9557\n",
            "Epoch 00030: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 470us/step - loss: 0.1204 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2716 - val_sparse_categorical_accuracy: 0.9220\n",
            "Epoch 31/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1175 - sparse_categorical_accuracy: 0.9566\n",
            "Epoch 00031: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 29s 476us/step - loss: 0.1174 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.2440 - val_sparse_categorical_accuracy: 0.9235\n",
            "Epoch 32/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1141 - sparse_categorical_accuracy: 0.9566\n",
            "Epoch 00032: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9565 - val_loss: 0.2626 - val_sparse_categorical_accuracy: 0.9253\n",
            "Epoch 33/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1148 - sparse_categorical_accuracy: 0.9572\n",
            "Epoch 00033: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.1148 - sparse_categorical_accuracy: 0.9572 - val_loss: 0.2576 - val_sparse_categorical_accuracy: 0.9273\n",
            "Epoch 34/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1086 - sparse_categorical_accuracy: 0.9589\n",
            "Epoch 00034: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.1085 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.2716 - val_sparse_categorical_accuracy: 0.9248\n",
            "Epoch 35/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1074 - sparse_categorical_accuracy: 0.9596\n",
            "Epoch 00035: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 472us/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.2549 - val_sparse_categorical_accuracy: 0.9275\n",
            "Epoch 36/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1053 - sparse_categorical_accuracy: 0.9608\n",
            "Epoch 00036: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 463us/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.2676 - val_sparse_categorical_accuracy: 0.9271\n",
            "Epoch 37/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1082 - sparse_categorical_accuracy: 0.9603\n",
            "Epoch 00037: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.1083 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.2579 - val_sparse_categorical_accuracy: 0.9274\n",
            "Epoch 38/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1012 - sparse_categorical_accuracy: 0.9624\n",
            "Epoch 00038: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 471us/step - loss: 0.1013 - sparse_categorical_accuracy: 0.9624 - val_loss: 0.2862 - val_sparse_categorical_accuracy: 0.9222\n",
            "Epoch 39/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1013 - sparse_categorical_accuracy: 0.9624\n",
            "Epoch 00039: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 465us/step - loss: 0.1013 - sparse_categorical_accuracy: 0.9624 - val_loss: 0.2603 - val_sparse_categorical_accuracy: 0.9263\n",
            "Epoch 40/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1019 - sparse_categorical_accuracy: 0.9636\n",
            "Epoch 00040: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 27s 456us/step - loss: 0.1018 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.2675 - val_sparse_categorical_accuracy: 0.9238\n",
            "Epoch 41/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0980 - sparse_categorical_accuracy: 0.9641\n",
            "Epoch 00041: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 464us/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.2555 - val_sparse_categorical_accuracy: 0.9295\n",
            "Epoch 42/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0956 - sparse_categorical_accuracy: 0.9654\n",
            "Epoch 00042: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9654 - val_loss: 0.2966 - val_sparse_categorical_accuracy: 0.9233\n",
            "Epoch 43/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0974 - sparse_categorical_accuracy: 0.9650\n",
            "Epoch 00043: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 473us/step - loss: 0.0973 - sparse_categorical_accuracy: 0.9650 - val_loss: 0.2602 - val_sparse_categorical_accuracy: 0.9294\n",
            "Epoch 44/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0904 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 00044: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 467us/step - loss: 0.0903 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.2782 - val_sparse_categorical_accuracy: 0.9277\n",
            "Epoch 45/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0930 - sparse_categorical_accuracy: 0.9659\n",
            "Epoch 00045: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 29s 477us/step - loss: 0.0929 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.2684 - val_sparse_categorical_accuracy: 0.9300\n",
            "Epoch 46/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0902 - sparse_categorical_accuracy: 0.9667\n",
            "Epoch 00046: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 29s 478us/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.2763 - val_sparse_categorical_accuracy: 0.9309\n",
            "Epoch 47/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0872 - sparse_categorical_accuracy: 0.9679\n",
            "Epoch 00047: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 29s 477us/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.2668 - val_sparse_categorical_accuracy: 0.9272\n",
            "Epoch 48/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0861 - sparse_categorical_accuracy: 0.9686\n",
            "Epoch 00048: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 29s 476us/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9686 - val_loss: 0.2799 - val_sparse_categorical_accuracy: 0.9263\n",
            "Epoch 49/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0877 - sparse_categorical_accuracy: 0.9680\n",
            "Epoch 00049: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 474us/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.2574 - val_sparse_categorical_accuracy: 0.9285\n",
            "Epoch 50/50\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0818 - sparse_categorical_accuracy: 0.9701\n",
            "Epoch 00050: saving model to ./output/weights.best.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "60000/60000 [==============================] - 28s 470us/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.2818 - val_sparse_categorical_accuracy: 0.9294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcedd45f630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ESL6ltQTMm05"
      },
      "cell_type": "markdown",
      "source": [
        "# Checking our results (inference)\n",
        "\n",
        "Now that we're done training, let's see how well we can predict fashion categories!  Keras/TPU prediction isn't working due to a small bug (fixed in TF 1.12!), but we can predict on the CPU to see how our results look."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SaYPv_aKId2d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LABEL_NAMES = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']\n",
        "\n",
        "\n",
        "#cpu_model = tpu_model.sync_to_cpu()\n",
        "\n",
        "from matplotlib import pyplot\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_predictions(images, predictions):\n",
        "  n = images.shape[0]\n",
        "  nc = int(np.ceil(n / 4))\n",
        "  f, axes = pyplot.subplots(nc, 4)\n",
        "  for i in range(nc * 4):\n",
        "    y = i // 4\n",
        "    x = i % 4\n",
        "    axes[x, y].axis('off')\n",
        "    \n",
        "    label = LABEL_NAMES[np.argmax(predictions[i])]\n",
        "    confidence = np.max(predictions[i])\n",
        "    if i > n:\n",
        "      continue\n",
        "    axes[x, y].imshow(images[i])\n",
        "    axes[x, y].text(0.5, 0.5, label + '\\n%.3f' % confidence, fontsize=14)\n",
        "\n",
        "  pyplot.gcf().set_size_inches(8, 8)  \n",
        "\n",
        "#plot_predictions(np.squeeze(x_test[:16]), \n",
        "                 #cpu_model.predict(x_test[:16]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GJAaFlQYNhoW"
      },
      "cell_type": "markdown",
      "source": [
        "# Not bad!"
      ]
    },
    {
      "metadata": {
        "id": "IvGtEfQ0Mkqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "a5c93447-356e-4808-901f-b7b8fcd64acb"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model = load_model(\"./logs/weights.best.hdf5\")\n",
        "plot_predictions(np.squeeze(x_test[:16]), \n",
        "                 new_model.predict(x_test[:16]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAHqCAYAAACugP9FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4mJyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9643ddd550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "0z5uc0tmPpKT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)\n",
        "import h5py\n",
        "print(h5py.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3WJFdv2yoVPH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**this section is for trainng GAN model of fashion mnist**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Uf0Ldb32rWjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4688
        },
        "outputId": "c8f61cd3-2ca4-43bf-bfb9-66ce3a89a2a7"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from gan_model import DCGAN\n",
        "\n",
        "import sys , os\n",
        "\n",
        "\n",
        "if not os.path.exists(\"./samples/fashion_mnist\"):\n",
        "    os.makedirs(\"./samples/fashion_mnist\")\n",
        "    \n",
        "if not os.path.exists(\"./checkpoints\"):\n",
        "    os.makedirs(\"./checkpoints\")\n",
        "    \n",
        "\n",
        "# write all the output to file\n",
        "'''original_std = sys.stdout\n",
        "f  = open ('./output.txt','w')\n",
        "sys.stdout = f'''\n",
        "\n",
        "flags  = tf.app.flags\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "\n",
        "flags.DEFINE_integer(\"epoch\", 2000, \"Epoch to train [250]\")\n",
        "flags.DEFINE_integer(\"batch_size\", 64, \"The number of batch images [64]\")\n",
        "flags.DEFINE_integer(\"sample_size\", 28, \"The number of sample images [64]\")\n",
        "flags.DEFINE_integer(\"c_dim\", 1, \"Dimension of image color. [3]\")\n",
        "flags.DEFINE_integer(\"save_step\", 100, \"The interval of saveing checkpoints. [500]\")\n",
        "flags.DEFINE_string(\"dataset\", \"fashion_mnist\", \"The name of dataset [fashion_mnist, mnist]\")\n",
        "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoints\", \"Directory name to save the checkpoints [checkpoints]\")\n",
        "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Directory name to save the image samples [samples]\")\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    # Print flags\n",
        "    print(\"\\n---------FLAGS-----------\")\n",
        "    for flag, _ in FLAGS.__flags.items():\n",
        "        print('\"{}\": {}'.format(flag, getattr(FLAGS, flag)))\n",
        "      \n",
        "    print(\"--------------------\\n\")\n",
        "\n",
        "    dcgan = DCGAN()\n",
        "    dcgan()\n",
        "    #dcgan.train()\n",
        "    '''sys.stdout = original_std\n",
        "    f.close()'''\n",
        "\n",
        "   \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------FLAGS-----------\n",
            "\"helpfull\": False\n",
            "\"help\": False\n",
            "\"sample_dir\": samples\n",
            "\"h\": False\n",
            "\"batch_size\": 64\n",
            "\"dataset\": fashion_mnist\n",
            "\"helpshort\": False\n",
            "\"sample_size\": 28\n",
            "\"epoch\": 2000\n",
            "\"save_step\": 100\n",
            "\"checkpoint_dir\": checkpoints\n",
            "\"c_dim\": 1\n",
            "--------------------\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 4097      \n",
            "=================================================================\n",
            "Total params: 393,729\n",
            "Trainable params: 392,833\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 1)         577       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 856,193\n",
            "Trainable params: 855,809\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-70bd0454dc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-70bd0454dc30>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mdcgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mdcgan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#dcgan.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gan_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m     76\u001b[0m                         tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'] ))\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_to_tpu_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m     self._cpu_model.compile(\n\u001b[0;32m-> 1402\u001b[0;31m         \u001b[0m_clone_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mmetrics_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mmetrics_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.pyc\u001b[0m in \u001b[0;36m_clone_optimizer\u001b[0;34m(optimizer, config)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cloning %s %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    500\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     config = {\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;34m'beta_1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;34m'beta_2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/backend.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2707\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2709\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trying to eval in EAGER mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5155\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5157\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable Adam/lr from Container: worker. This could mean that the variable was uninitialized. Not found: Resource worker/Adam/lr/N10tensorflow3VarE does not exist.\n\t [[node Adam/lr/Read/ReadVariableOp (defined at gan_model.py:41)  = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](Adam/lr)]]\n\nCaused by op u'Adam/lr/Read/ReadVariableOp', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-70bd0454dc30>\", line 52, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-1-70bd0454dc30>\", line 43, in main\n    dcgan = DCGAN()\n  File \"gan_model.py\", line 41, in __init__\n    self.optimizer = Adam(0.0002, 0.5)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/optimizers.py\", line 446, in __init__\n    self.lr = K.variable(lr, name='lr')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/backend.py\", line 683, in variable\n    constraint=constraint)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 297, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 449, in _init_from_args\n    value = self._read_variable_op()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 727, in _read_variable_op\n    self._dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 508, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable Adam/lr from Container: worker. This could mean that the variable was uninitialized. Not found: Resource worker/Adam/lr/N10tensorflow3VarE does not exist.\n\t [[node Adam/lr/Read/ReadVariableOp (defined at gan_model.py:41)  = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](Adam/lr)]]\n"
          ]
        }
      ]
    }
  ]
}
